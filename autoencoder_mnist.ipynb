{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('./ae_mnist'):\n",
    "    os.mkdir('./ae_mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalization(tensor, min_value, max_value):\n",
    "    min_tensor = tensor.min()\n",
    "    tensor = (tensor - min_tensor)\n",
    "    max_tensor = tensor.max()\n",
    "    tensor = tensor / max_tensor\n",
    "    tensor = tensor * (max_value - min_value) + min_value\n",
    "    return tensor\n",
    "\n",
    "def tensor_round(tensor):\n",
    "    return torch.round(tensor)\n",
    "\n",
    "def to_img(x):\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda tensor:min_max_normalization(tensor, 0, 1)),\n",
    "    transforms.Lambda(lambda tensor:tensor_round(tensor))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST('', transform=img_transform, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for data in dataloader:\n",
    "    break;\n",
    "data[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 30\n",
    "plt.imshow(data[0][i].view((28, 28)))\n",
    "print(f'Label: {data[1][i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on the GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('running on the GPU')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('running on the CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoEncoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=256, out_features=64, bias=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=256, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=256, out_features=784, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(64, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 28*28),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(self.encoder(x))\n",
    "        \n",
    "model = AutoEncoder().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(), lr=1e-3, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size = 1\n",
    "# random_start = np.random.randint(len(dataset)-size)\n",
    "# print(random_start)\n",
    "# random_range = range(random_start, random_start+size)\n",
    "# random_batch = torch.utils.data.Subset(dataset, random_range)\n",
    "# random_loader = DataLoader(random_batch, batch_size=1, num_workers=1)\n",
    "# for data in random_loader:\n",
    "#     break\n",
    "# img, _ = data\n",
    "# img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fwd_pass(img, train=False):\n",
    "#     outputs = model(img)\n",
    "#     BCE_loss = criterion(outputs, img)\n",
    "#     MSE_loss = nn.MSELoss()(outputs, img)\n",
    "    \n",
    "#     if train:\n",
    "#         model.zero_grad()\n",
    "#         BCE_loss.backward()\n",
    "#         optimizer.step()\n",
    "    \n",
    "#     return BCE_loss, MSE_loss\n",
    "\n",
    "# def test(size=128):\n",
    "#     random_start = np.random.randint(len(dataset)-size)\n",
    "#     random_range = range(random_start, random_start+size)\n",
    "#     random_batch = torch.utils.data.Subset(dataset, random_range)\n",
    "#     random_loader = DataLoader(random_batch, batch_size=128, num_workers=1)\n",
    "#     for data in random_loader:\n",
    "#         break\n",
    "#     img, _ = data\n",
    "#     with torch.no_grad():\n",
    "#         val_BCEloss, val_MSEloss = fwd_pass(img.to(device))\n",
    "    \n",
    "#     return val_BCEloss, val_MSEloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/469 [00:00<00:12, 37.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-1595575843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:09<00:00, 51.35it/s]\n",
      "\n",
      "100%|██████████| 96/96 [00:00<00:00, 2073.14it/s]\n",
      "  1%|          | 5/469 [00:00<00:10, 42.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch [1/100], loss:0.0471, MSE_loss:0.0137\n",
      "torch.Size([96, 1, 28, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 184/469 [00:03<00:05, 49.62it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-980072dbcb32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#         i = 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'ae_mnist_{MODEL_NAME}.log'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1105\u001b[0m                 fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m   1106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1107\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1108\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-7d5a8066967a>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(tensor)\u001b[0m\n\u001b[1;32m      1\u001b[0m img_transform = transforms.Compose([\n\u001b[1;32m      2\u001b[0m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmin_max_normalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtensor_round\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m ])\n",
      "\u001b[0;32m<ipython-input-3-6811ad7057a2>\u001b[0m in \u001b[0;36mmin_max_normalization\u001b[0;34m(tensor, min_value, max_value)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmax_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmax_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_value\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmin_value\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmin_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 184/469 [00:18<00:05, 49.62it/s]"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = f'model-{int(time.time())}'\n",
    "print(MODEL_NAME)\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "#         i = 0\n",
    "    with open(f'ae_mnist_{MODEL_NAME}.log', 'a') as f:\n",
    "        for data in tqdm(dataloader, position=0, leave=True):\n",
    "            img, _ = data\n",
    "            img = img.view(img.size(0), -1)\n",
    "            img = Variable(img).to(device)\n",
    "            # ===================forward=====================\n",
    "            output = model(img)\n",
    "            loss = criterion(output, img)\n",
    "            MSE_loss = nn.MSELoss()(output, img)\n",
    "            # ===================backward====================\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    #             BCE_loss, MSE_loss = fwd_pass(img, train=True)\n",
    "    #             if i % 5 == 0:\n",
    "    #                 val_BCEloss, val_MSEloss = test()\n",
    "    #                 f.write(f'{MODEL_NAME},{round(time.time(), 3)},'\\\n",
    "    #                         f'{round(float(BCE_loss), 4)},{round(float(MSE_loss), 4)},'\\\n",
    "    #                         f'{round(float(val_BCEloss), 4)},{round(float(val_MSEloss), 4)}\\n')\n",
    "        # ===================log========================\n",
    "        \n",
    "        print(f'epoch [{epoch+1}/{num_epochs}], '\\\n",
    "              f'loss:{loss.data.item():.4f}, MSE_loss:{MSE_loss.data.item():.4f}')\n",
    "        f.write(f'{epoch+1},{round(time.time(), 3)},'\\\n",
    "                f'{loss.data.item():.4f},{MSE_loss.data.item():.4f}\\n')\n",
    "    if epoch % 5 == 0:\n",
    "        x = to_img(img.cpu().data)\n",
    "        x_hat = to_img(output.cpu().data)\n",
    "        save_image(x, f'./ae_mnist/x_{epoch}.png')\n",
    "        save_image(x_hat, f'./ae_mnist/x_hat_{epoch}.png')\n",
    "        \n",
    "torch.save(model.state_dict(), f'./ae_minist_{MODEL_NAME}_statedict.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for data in dataloader:\n",
    "    break\n",
    "img, _ = data\n",
    "img = img.view(img.size(0), -1)\n",
    "img = Variable(img).to(device)\n",
    "x = to_img(img.cpu().data)\n",
    "x.shape[0]\n",
    "# for i in tqdm(range(img.size(0))):\n",
    "#     save_image(img[i,:,:,:], f'test{i}.png')\n",
    "# save_image(img, 'test_save_batch.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
